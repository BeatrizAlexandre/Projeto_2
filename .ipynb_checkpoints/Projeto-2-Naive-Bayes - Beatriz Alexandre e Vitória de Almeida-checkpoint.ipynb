{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "## Por: Beatriz Alexandre e Vitória de Almeida\n",
    "\n",
    "### Marca: Lindt\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl  \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colocando os dados em um DataFrame\n",
    "\n",
    "Lendo o arquivo Excel Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Positivo/Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate is so overrated</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@elgliko hear that pitter patter in the back g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @statutory_boy: the guy was addicted to dru...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@andreyasasylum @yourmomsuckstho hey, can you ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job by @noticgroup gms. come and see the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante  \\\n",
       "0                    lindt chocolate is so overrated        1.0   \n",
       "1  @elgliko hear that pitter patter in the back g...        0.0   \n",
       "2  rt @statutory_boy: the guy was addicted to dru...        0.0   \n",
       "3  @andreyasasylum @yourmomsuckstho hey, can you ...        1.0   \n",
       "4  great job by @noticgroup gms. come and see the...        1.0   \n",
       "\n",
       "  Positivo/Negativo  \n",
       "0                 0  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = pd.read_excel('tweets_lindt.xlsx', sheet_name = 0)\n",
    "\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando os tweets\n",
    "\n",
    "Nessa etapa retirou se pontuação, @, \\n, \\t, deu espaço entre os emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate is so overrated</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elgliko hear that pitter patter in the back gr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt statutoryboy the guy was addicted to drugs ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andreyasasylum yourmomsuckstho hey can you ple...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job by noticgroup gms come and see them ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0                    lindt chocolate is so overrated        1.0\n",
       "1  elgliko hear that pitter patter in the back gr...        0.0\n",
       "2  rt statutoryboy the guy was addicted to drugs ...        0.0\n",
       "3  andreyasasylum yourmomsuckstho hey can you ple...        1.0\n",
       "4  great job by noticgroup gms come and see them ...        1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "ponto = string.punctuation\n",
    "\n",
    "#lista para depoi tirar os pontos\n",
    "po = [\"\\n\", \"\\t\"]\n",
    "\n",
    "data_limpo = []\n",
    "\n",
    "#dar espaço nos emojis e limpar os pontos\n",
    "for tweet in tw[\"Treinamento\"]:\n",
    "    t = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            t = t+ \" \" + palavra + \" \"\n",
    "        elif palavra in po:\n",
    "            t += \" \"\n",
    "        elif palavra not in ponto:\n",
    "            t += palavra\n",
    "    data_limpo.append(t)\n",
    "\n",
    "tw_li =  pd.DataFrame()\n",
    "tw_li['Treinamento'] = data_limpo\n",
    "tw_li['Relevante'] = tw['Relevante']\n",
    "\n",
    "tw_li.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate overrated</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elgliko hear that pitter patter the back groun...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statutoryboy the guy was addicted drugs his li...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andreyasasylum yourmomsuckstho hey can you ple...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job noticgroup gms come and see them and...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0                          lindt chocolate overrated        1.0\n",
       "1  elgliko hear that pitter patter the back groun...        0.0\n",
       "2  statutoryboy the guy was addicted drugs his li...        0.0\n",
       "3  andreyasasylum yourmomsuckstho hey can you ple...        1.0\n",
       "4  great job noticgroup gms come and see them and...        1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tirar os @ e os #\n",
    "data_limpo = []\n",
    "x= ' '\n",
    "for tweet in tw_li['Treinamento']:\n",
    "    limp = []\n",
    "    spli = tweet.split()\n",
    "    for palavra in spli:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limp.append(palavra)\n",
    "        elif len(palavra) > 2 and palavra[0]!='@' and palavra[0] != '#' and palavra[:4] != \"http\":\n",
    "            limp.append(palavra)\n",
    "        elif palavra == tweet[-1] and (\"...\" in palavra):\n",
    "            limp = ''\n",
    "        \n",
    "    data_limpo.append(x.join(limp))\n",
    "    \n",
    "tw_limpo =  pd.DataFrame()\n",
    "tw_limpo['Treinamento'] = data_limpo\n",
    "tw_limpo['Relevante'] = tw['Relevante']\n",
    "#Algumas palavras de alguns tweets travam o programa, então por isso é preciso trocar essas palavras por outra\n",
    "tw_limpo['Treinamento'] = tw_limpo['Treinamento'].str.replace('gorgeous\\xa0i', 'banana')\n",
    "\n",
    "\n",
    "tw_limpo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lista de todas as palavras dos tweets\n",
    "\n",
    "Foi preciso criar uma lista com todas as palavras dos tweets, para posteriormente poder calcular a frequência e depois a probabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pala = []\n",
    "\n",
    "for i in tw_limpo['Treinamento']:\n",
    "    frase = i.split()\n",
    "    for p in frase:\n",
    "        if p not in pala:\n",
    "            pala.append(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar quantas vezes aparace o 1 (Relevante) e o 0 (não relevante):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contador\n",
    "Rel = 0\n",
    "Irre = 0 \n",
    "\n",
    "for l in range(len(tw_limpo)):\n",
    "    linha = tw_limpo[\"Treinamento\"][l].split(\" \")\n",
    "    for i in linha:\n",
    "\n",
    "        if tw_limpo[\"Relevante\"][l] == 1:\n",
    "            Rel += 1\n",
    "        else:\n",
    "            Irre += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicionários para calcular a frequência de relevantes e irrelevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionou as palavras no dicionário de frequencia\n",
    "r_freq = {}\n",
    "ir_freq = {}\n",
    "\n",
    "for palavras in pala:\n",
    "    r_freq[palavras] = 1\n",
    "    ir_freq[palavras] = 1\n",
    "\n",
    "for g in range(len(tw_limpo)):\n",
    "    linha = tw_limpo[\"Treinamento\"][g].split(\" \")\n",
    "    for v in linha:\n",
    "        if tw_limpo[\"Relevante\"][g] == 0:\n",
    "            ir_freq[v]+=1\n",
    "        else:\n",
    "            r_freq[v]+= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade de ser relevante da cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_prob = {}\n",
    "ir_prob = {}\n",
    "\n",
    "#pala é a lista de palavras dos tweets\n",
    "\n",
    "for palavra in pala:\n",
    "    r_prob[palavra] = (r_freq[palavra]+1)/(len(pala)+Rel)\n",
    "    ir_prob[palavra] = (ir_freq[palavra]+1)/(len(pala)+Irre)\n",
    "    \n",
    "print(r_prob['lindt'],r_freq[palavra]+1,len(pala),Rel)\n",
    "print(ir_prob['lindt'],ir_freq[palavra]+1,len(pala),Irre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(relevante) e P(irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevante = 0\n",
    "relevante = 0 \n",
    "for m in tw_limpo['Relevante']:\n",
    "    if m == 0:\n",
    "        irrelevante += 1\n",
    "    else:\n",
    "        relevante += 1 \n",
    "Pr = relevante/len(tw_limpo['Relevante'])\n",
    "Pi = 1-Pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# TESTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colocando o arquivo Excel em um DataFrama\n",
    "\n",
    "Nessa etapa lê-se o arquivo Teste do Excel e coloca o em um DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g é o DataFrame do Teste!\n",
    "g = pd.read_excel('tweets_lindt.xlsx', sheet_name = 1)\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando os tweets do teste\n",
    "\n",
    "É preciso limpar tweets, retirando a pontuação, @, # e dando espaço entre os emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.Teste = g.Teste.str.replace('@', '')\n",
    "g.Teste = g.Teste.str.replace(':', '')\n",
    "g.Teste = g.Teste.str.replace('-', '')\n",
    "g.Teste = g.Teste.str.replace('_', '')\n",
    "g.Teste = g.Teste.str.replace(',', '')\n",
    "g.Teste = g.Teste.str.replace('!', '')\n",
    "g.Teste = g.Teste.str.replace('(', '')\n",
    "g.Teste = g.Teste.str.replace(')', '')\n",
    "g.Teste = g.Teste.str.replace('=', '')\n",
    "g.Teste = g.Teste.str.replace('*', '')\n",
    "g.Teste = g.Teste.str.replace('#', '')\n",
    "\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_espaco_emoji = []\n",
    "data = g[\"Teste\"]\n",
    "for tweet in data:\n",
    "    t = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            t = t+ \" \" + palavra + \" \"\n",
    "        else:\n",
    "            t += palavra\n",
    "    g_espaco_emoji.append(t)\n",
    "\n",
    "g_limpo =  pd.DataFrame()\n",
    "g_limpo['Teste'] = g_espaco_emoji\n",
    "g_limpo['Relevante'] = g['Relevante']\n",
    "\n",
    "g_limpo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculando as Probabilidades no Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = []\n",
    "j = []\n",
    "k = []\n",
    "for f in g_limpo['Teste']:\n",
    "    comR = 1\n",
    "    comIr = 1\n",
    "    x = f.split(' ')\n",
    "    \n",
    "    for palavra in x:\n",
    "        \n",
    "        if palavra in ir_prob:\n",
    "            comIr *= ir_prob[palavra]\n",
    "        else:\n",
    "            comIr *= 1/(len(pala)+Irre)\n",
    "        if palavra in r_prob:\n",
    "            comR *= r_prob[palavra]\n",
    "        else:\n",
    "            comR *= 1/(len(pala)+Rel)\n",
    "\n",
    "    Rp = comR*Pr\n",
    "    Irp = comIr*Pi\n",
    "    \n",
    "    j.append(Rp)\n",
    "    k.append(Irp)\n",
    "    \n",
    "    if Rp >= Irp:\n",
    "        lista_teste.append(1)\n",
    "    else:\n",
    "        lista_teste.append(0)\n",
    "min(k)\n",
    "g[\"lista teste\"] = lista_teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprimir as probabilidades de positivo e negativo verdadeiros e falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = g.loc[(g['Relevante'] == 1 ) & (g['lista teste'] == 1 ), ['Relevante', 'lista teste']]\n",
    "uz = g.loc[(g['Relevante'] == 0 ) & (g['lista teste'] == 1 ), ['Relevante', 'lista teste']]\n",
    "zz = g.loc[(g['Relevante'] == 0 ) & (g['lista teste'] == 0 ), ['Relevante', 'lista teste']]\n",
    "zu = g.loc[(g['Relevante'] == 1 ) & (g['lista teste'] == 0 ), ['Relevante', 'lista teste']]\n",
    "\n",
    "posV = (len(uu)/len(g['Relevante']))*100\n",
    "posF = (len(uz)/len(g['Relevante']))*100\n",
    "negV = (len(zz)/len(g['Relevante']))*100\n",
    "negF = (len(zu)/len(g['Relevante']))*100\n",
    "\n",
    "print('Relevantes verdadeiros = {:.3f}%'.format(posV))\n",
    "print('Relevantes falsos = {:.3f}%'.format(posF))\n",
    "print('Irrelevantes verdadeiros = {:.3f}%'.format(negV))\n",
    "print('Irrelevantes falsos = {:.3f}%'.format(negF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observações\n",
    "\n",
    "\n",
    "* Foram impressos todos os DataFrames para garantir que os comandos dados foram eftivados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Depois de ter o código classificador pronto e utilizá-lo para o Teste, conclui-se que a marca Lindt tem uma maior quantidade de tweets relevantes verdadeiros (44%) do que de relevantes falsos (20%), o que mostra que o classificador é eficiente e a taxa de acerto dele é de 77%. Para a empresa é bom ter os relevantes falsos, pois assim a probabilidade dela analisar todos os tweets que devem ser analisados é muito maior e ela precisa, apenas, retirar os falsos manualmente.\n",
    "   \n",
    "  A Lindt deveria continuar a financiar o projeto naive-bayes, pois, com ele, eles conseguem saber o que o seu público alvo pensa sobre seus produtos. Logo, a Lindt sabe o que deve aprimorar e o que deve continuar a fazer.\n",
    "  \n",
    "  Para o classificador ser ainda mais eficaz, é bom criar outras categorias além de relevante e irrelevante.\n",
    "  \n",
    "  Quando a Lindt quiser mudar seu banco de dados para outros tweets, ela deve prestar atenção para não selecionar o Treinamento, pois caso isso aconteça a probabilidade será 100% já que o código classificador foi criado com base no mesmo. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split: https://www.tutorialspoint.com/python/string_split.htm\n",
    "* Tutorial\n",
    "* Naive-Bayes: https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
