{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "## Por: Beatriz Alexandre e Vitória de Almeida\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl  \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Colocando os dados em um DataFrame\n",
    "\n",
    "Lendo o arquivo Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Positivo/Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate is so overrated</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@elgliko hear that pitter patter in the back g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @statutory_boy: the guy was addicted to dru...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@andreyasasylum @yourmomsuckstho hey, can you ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job by @noticgroup gms. come and see the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante  \\\n",
       "0                    lindt chocolate is so overrated        1.0   \n",
       "1  @elgliko hear that pitter patter in the back g...        0.0   \n",
       "2  rt @statutory_boy: the guy was addicted to dru...        0.0   \n",
       "3  @andreyasasylum @yourmomsuckstho hey, can you ...        1.0   \n",
       "4  great job by @noticgroup gms. come and see the...        1.0   \n",
       "\n",
       "  Positivo/Negativo  \n",
       "0                 0  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw = pd.read_excel('tweets_lindt.xlsx', sheet_name = 0)\n",
    "\n",
    "tw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpando os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate is so overrated</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elgliko hear that pitter patter in the back gr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt statutoryboy the guy was addicted to drugs ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andreyasasylum yourmomsuckstho hey can you ple...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job by noticgroup gms come and see them ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0                    lindt chocolate is so overrated        1.0\n",
       "1  elgliko hear that pitter patter in the back gr...        0.0\n",
       "2  rt statutoryboy the guy was addicted to drugs ...        0.0\n",
       "3  andreyasasylum yourmomsuckstho hey can you ple...        1.0\n",
       "4  great job by noticgroup gms come and see them ...        1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "ponto = string.punctuation\n",
    "\n",
    "#lista para depoi tirar os pontos\n",
    "po = [\"\\n\", \"\\t\"]\n",
    "\n",
    "data_limpo = []\n",
    "\n",
    "#dar espaço nos emojis e limpar os pontos\n",
    "for tweet in tw[\"Treinamento\"]:\n",
    "    t = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            t = t+ \" \" + palavra + \" \"\n",
    "        elif palavra in po:\n",
    "            t += \" \"\n",
    "        elif palavra not in ponto:\n",
    "            t += palavra\n",
    "    data_limpo.append(t)\n",
    "\n",
    "tw_li =  pd.DataFrame()\n",
    "tw_li['Treinamento'] = data_limpo\n",
    "tw_li['Relevante'] = tw['Relevante']\n",
    "\n",
    "tw_li.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lindt chocolate overrated</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elgliko hear that pitter patter the back groun...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statutoryboy the guy was addicted drugs his li...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>andreyasasylum yourmomsuckstho hey can you ple...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great job noticgroup gms come and see them and...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relevante\n",
       "0                          lindt chocolate overrated        1.0\n",
       "1  elgliko hear that pitter patter the back groun...        0.0\n",
       "2  statutoryboy the guy was addicted drugs his li...        0.0\n",
       "3  andreyasasylum yourmomsuckstho hey can you ple...        1.0\n",
       "4  great job noticgroup gms come and see them and...        1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tirar os @ e os #\n",
    "data_limpo = []\n",
    "x= ' '\n",
    "for tweet in tw_li['Treinamento']:\n",
    "    limp = []\n",
    "    spli = tweet.split()\n",
    "    for palavra in spli:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limp.append(palavra)\n",
    "        elif len(palavra) > 2 and palavra[0]!='@' and palavra[0] != '#' and palavra[:4] != \"http\":\n",
    "            limp.append(palavra)\n",
    "        elif palavra == tweet[-1] and (\"...\" in palavra):\n",
    "            limp = ''\n",
    "        \n",
    "    data_limpo.append(x.join(limp))\n",
    "    \n",
    "tw_limpo =  pd.DataFrame()\n",
    "tw_limpo['Treinamento'] = data_limpo\n",
    "tw_limpo['Relevante'] = tw['Relevante']\n",
    "#Agumas palavras de alguns tweets travam o programa, então por isso é preciso trocar essas palavras por outra\n",
    "tw_limpo['Treinamento'] = tw_limpo['Treinamento'].str.replace('gorgeous\\xa0i', 'banana')\n",
    "\n",
    "\n",
    "tw_limpo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista de todas as palavras dos tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pala = []\n",
    "\n",
    "for i in tw_limpo['Treinamento']:\n",
    "    frase = i.split()\n",
    "    for p in frase:\n",
    "        if p not in pala:\n",
    "            pala.append(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contar quantas vezes aparace o 1 (Relevante) e o 0 (não relevante):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contador\n",
    "Rel = 0\n",
    "Irre = 0 \n",
    "\n",
    "for l in range(len(tw_limpo)):\n",
    "    linha = tw_limpo[\"Treinamento\"][l].split(\" \")\n",
    "    for i in linha:\n",
    "\n",
    "        if tw_limpo[\"Relevante\"][l] == 1:\n",
    "            Rel += 1\n",
    "        else:\n",
    "            Irre += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicionários para calcular a frequencia de relevantes e irrelevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adicionou as palavras no dicionário de frequencia\n",
    "r_freq = {}\n",
    "ir_freq = {}\n",
    "\n",
    "for palavras in pala:\n",
    "    r_freq[palavras] = 1\n",
    "    ir_freq[palavras] = 1\n",
    "\n",
    "for g in range(len(tw_limpo)):\n",
    "    linha = tw_limpo[\"Treinamento\"][g].split(\" \")\n",
    "    for v in linha:\n",
    "        if tw_limpo[\"Relevante\"][g] == 0:\n",
    "            ir_freq[v]+=1\n",
    "        else:\n",
    "            r_freq[v]+= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A probabilidade de ser relevante da cada palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030652280529671408 2 1906 2172\n",
      "0.0050335570469798654 3 1906 2266\n"
     ]
    }
   ],
   "source": [
    "r_prob = {}\n",
    "ir_prob = {}\n",
    "\n",
    "#pala é a lista de palavras dos tweets\n",
    "\n",
    "for palavra in pala:\n",
    "    r_prob[palavra] = (r_freq[palavra]+1)/(len(pala)+Rel)\n",
    "    ir_prob[palavra] = (ir_freq[palavra]+1)/(len(pala)+Irre)\n",
    "    \n",
    "print(r_prob['lindt'],r_freq[palavra]+1,len(pala),Rel)\n",
    "print(ir_prob['lindt'],ir_freq[palavra]+1,len(pala),Irre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(relevante) e P(irrelevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevante = 0\n",
    "relevante = 0 \n",
    "for m in tw_limpo['Relevante']:\n",
    "    if m == 0:\n",
    "        irrelevante += 1\n",
    "    else:\n",
    "        relevante += 1 \n",
    "Pr = relevante/len(tw_limpo['Relevante'])\n",
    "Pi = 1-Pr\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Positivo/Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @thembarumbu: dear ladies\\nif you catch ur ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @dailytelegraph: one of the most notorious ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commercial law's bitch ...is what i am right n...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@hloni_maniers i'm craving lindt lindor 😫</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt @lutho__m: if you're reading this tweet htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevante  \\\n",
       "0  rt @thembarumbu: dear ladies\\nif you catch ur ...          0   \n",
       "1  rt @dailytelegraph: one of the most notorious ...          1   \n",
       "2  commercial law's bitch ...is what i am right n...          0   \n",
       "3          @hloni_maniers i'm craving lindt lindor 😫          1   \n",
       "4  rt @lutho__m: if you're reading this tweet htt...          0   \n",
       "\n",
       "  Positivo/Negativo  \n",
       "0               NaN  \n",
       "1               0/1  \n",
       "2               NaN  \n",
       "3                 1  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g é o DataFrame do Teste!\n",
    "g = pd.read_excel('tweets_lindt.xlsx', sheet_name = 1)\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando os tweets do teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "      <th>Positivo/Negativo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt thembarumbu dear ladies\\nif you catch ur bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt dailytelegraph one of the most notorious ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0/1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commercial law's bitch ...is what i am right n...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hlonimaniers i'm craving lindt lindor 😫</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt luthom if you're reading this tweet https//...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevante  \\\n",
       "0  rt thembarumbu dear ladies\\nif you catch ur bo...          0   \n",
       "1  rt dailytelegraph one of the most notorious ba...          1   \n",
       "2  commercial law's bitch ...is what i am right n...          0   \n",
       "3            hlonimaniers i'm craving lindt lindor 😫          1   \n",
       "4  rt luthom if you're reading this tweet https//...          0   \n",
       "\n",
       "  Positivo/Negativo  \n",
       "0               NaN  \n",
       "1               0/1  \n",
       "2               NaN  \n",
       "3                 1  \n",
       "4               NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.Teste = g.Teste.str.replace('@', '')\n",
    "g.Teste = g.Teste.str.replace(':', '')\n",
    "g.Teste = g.Teste.str.replace('-', '')\n",
    "g.Teste = g.Teste.str.replace('_', '')\n",
    "g.Teste = g.Teste.str.replace(',', '')\n",
    "g.Teste = g.Teste.str.replace('!', '')\n",
    "g.Teste = g.Teste.str.replace('(', '')\n",
    "g.Teste = g.Teste.str.replace(')', '')\n",
    "g.Teste = g.Teste.str.replace('=', '')\n",
    "g.Teste = g.Teste.str.replace('*', '')\n",
    "g.Teste = g.Teste.str.replace('#', '')\n",
    "\n",
    "g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt thembarumbu dear ladies\\nif you catch ur bo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt dailytelegraph one of the most notorious ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>commercial law's bitch ...is what i am right n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hlonimaniers i'm craving lindt lindor  😫</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt luthom if you're reading this tweet https//...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relevante\n",
       "0  rt thembarumbu dear ladies\\nif you catch ur bo...          0\n",
       "1  rt dailytelegraph one of the most notorious ba...          1\n",
       "2  commercial law's bitch ...is what i am right n...          0\n",
       "3          hlonimaniers i'm craving lindt lindor  😫           1\n",
       "4  rt luthom if you're reading this tweet https//...          0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_espaco_emoji = []\n",
    "data = g[\"Teste\"]\n",
    "for tweet in data:\n",
    "    t = ''\n",
    "    for palavra in tweet:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            t = t+ \" \" + palavra + \" \"\n",
    "        else:\n",
    "            t += palavra\n",
    "    g_espaco_emoji.append(t)\n",
    "\n",
    "g_limpo =  pd.DataFrame()\n",
    "g_limpo['Teste'] = g_espaco_emoji\n",
    "g_limpo['Relevante'] = g['Relevante']\n",
    "\n",
    "g_limpo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando as Probabilidades no Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_teste = []\n",
    "j = []\n",
    "k = []\n",
    "for f in g_limpo['Teste']:\n",
    "    comR = 1\n",
    "    comIr = 1\n",
    "    x = f.split(' ')\n",
    "    \n",
    "    for palavra in x:\n",
    "        \n",
    "        if palavra in ir_prob:\n",
    "            comIr *= ir_prob[palavra]\n",
    "        else:\n",
    "            comIr *= 1/(len(pala)+Irre)\n",
    "        if palavra in r_prob:\n",
    "            comR *= r_prob[palavra]\n",
    "        else:\n",
    "            comR *= 1/(len(pala)+Rel)\n",
    "\n",
    "    Rp = comR*Pr\n",
    "    Irp = comIr*Pi\n",
    "    \n",
    "    j.append(Rp)\n",
    "    k.append(Irp)\n",
    "    \n",
    "    if Rp >= Irp:\n",
    "        lista_teste.append(1)\n",
    "    else:\n",
    "        lista_teste.append(0)\n",
    "min(k)\n",
    "g[\"lista teste\"] = lista_teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimir as probabilidades de positivo e negativo verdadeiros e falsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positivos verdadeiros = 44.000%\n",
      "Positivos falsos = 20.000%\n",
      "Negativos verdadeiros = 33.000%\n",
      "Negativos falsos = 3.000%\n"
     ]
    }
   ],
   "source": [
    "uu = g.loc[(g['Relevante'] == 1 ) & (g['lista teste'] == 1 ), ['Relevante', 'lista teste']]\n",
    "uz = g.loc[(g['Relevante'] == 0 ) & (g['lista teste'] == 1 ), ['Relevante', 'lista teste']]\n",
    "zz = g.loc[(g['Relevante'] == 0 ) & (g['lista teste'] == 0 ), ['Relevante', 'lista teste']]\n",
    "zu = g.loc[(g['Relevante'] == 1 ) & (g['lista teste'] == 0 ), ['Relevante', 'lista teste']]\n",
    "\n",
    "posV = (len(uu)/len(g['Relevante']))*100\n",
    "posF = (len(uz)/len(g['Relevante']))*100\n",
    "negV = (len(zz)/len(g['Relevante']))*100\n",
    "negF = (len(zu)/len(g['Relevante']))*100\n",
    "\n",
    "print('Positivos verdadeiros = {:.3f}%'.format(posV))\n",
    "print('Positivos falsos = {:.3f}%'.format(posF))\n",
    "print('Negativos verdadeiros = {:.3f}%'.format(negV))\n",
    "print('Negativos falsos = {:.3f}%'.format(negF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Depois de ter o código classificador pronto e utilizá-lo para o Teste, concluise-se que a marca Lindt tem uma maior probabilidade de seus tweets serem negativos, por um lado é ruim para marca, pois quer dizer que seus clientes não estão satisfeitos com os produtos. Porém alguns tweets positivos são contados como negativos no classificador, mas isso não é necessariamente prejudicial, pois no momento em que a empresa for analisar os tweets ela apenas o elimina e garante que todos os negativos serão analisados.\n",
    "  \n",
    "  A Lindt deveria continuar a financiar o projeto, pois com ele, eles conseguem saber o que o seu público alvo pensa sobre seus produtos. Logo, a Lindt sabe o que deve aprimorar e o que continuar a fazer. Para ele ser ainda mais eficaz é bom criar outras categorias além de relevante e irrelevante.\n",
    "  \n",
    "  Não se pode alimentar a base de treinamento usando o próprio classificador, pois o código classificador foi criado com base no Treinamento e por mais que aplique se novos tweets a base é a mesma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Split: https://www.tutorialspoint.com/python/string_split.htm\n",
    "* Tutorial\n",
    "* Naive-Bayes: https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
